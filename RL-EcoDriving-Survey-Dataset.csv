BibTeX Key,Title,RL Used (Yes/No),Eco-Driving (Yes/No),RL Category (MFRL/MBRL/HRL/MARL)
Eco_evo_1,"Eco-Driving and Its Impacts on Fuel Efficiency: An Overview of Technologies and Data-Driven Methods, JOURNAL = Sustainability",yes,yes,MFRL
Eco_evo_2,"Eco-driving technology for sustainable road transport: A review, journal = Renewable and Sustainable Energy Reviews",yes,yes,MFRL
Eco_evo_3,"Off-Policy Reinforcement based on a Safe Model Eco-Driving Education for Fully-Automated, Connected Hybrid Vehicles, year=2023",yes,yes,MFRL
Eco_evo_4,"About eco-driving, genesis, challenges and benefits, application possibilities, journal = Transportation Research Procedia",yes,yes,MBRL
Eco_evo_5,"training applications"", author    = ""Xu, Nan and Li, Xiaohan and Liu, Qiao and Zhao, Di"", journal   = ""Sensors (Basel)"", publisher = ""MDPI AG"", volume    =  21, number    =  19, pages     = ""6547"", month     =  sep, year      =  2021, language  = ""en""",yes,yes,MBRL
Eco_evo_6,"Eco-driving optimal control for electric vehicles with driver preferences, journal = Transportation Engineering",yes,yes,MFRL
RL_evo_1,"Deep Reinforcement Learning Based Integrated Eco-Driving Strategy for Connected and Automated Electric Vehicles in Complex Urban Scenarios, year=2024",yes,yes,MARL
RL_evo_2,"Application and Evaluation of the Reinforcement Learning Approach to Eco-Driving at Intersections under Infrastructure-to-Vehicle Communications, journal = Transportation Research Record",yes,yes,MFRL
RL_evo_3,"Safe Reinforcement Learning-Based Eco-Driving Control for Mixed Traffic Flows With Disturbances, author=Ke Lu and Dongjun Li and Qun Wang and Kaidi Yang and Lin Zhao and Ziyou Song",yes,yes,MARL
RL_evo_4,"author    = ""Ding, Haitao and Li, Wei and Xu, Nan and Zhang, Jianwei"", journal   = ""Journal of Intelligent and Connected Vehicles"", publisher = ""Emerald Publishing Limited"", volume    =  5, number    =  3, pages     = ""316--332"", month     =  jan, year      =  2022",no,yes,NAN
RL_evo_5,"author    = ""Jamil, Umar and Malmir, Mostafa and Chen, Alan and Filipovska, Monika and Xie, Mimi and Ding, Caiwen and Jin, Yu-Fang"", journal   = ""Sci. Prog."", publisher = ""SAGE Publications"", volume    =  107, number    =  3, pages     = ""368504241263406"", month     =  jul, year      =  2024, language  = ""en""",yes,yes,MBRL
RL_evo_6,"Learning Eco-Driving Strategies at Signalized Intersections, year=2022",yes,no,MFRL
RL_evo_7,"Hybrid Reinforcement Learning-Based Eco-Driving Strategy for Connected and Automated Vehicles at Signalized Intersections, year=2022",yes,yes,HRL
RL_evo_8,"A Deep Reinforcement Learning Framework for Eco-Driving in Connected and Automated Hybrid Electric Vehicles, year=2024",no,no,NAN
RL_evo_9,"Model-Based Reinforcement Learning for Eco-Driving Control of Electric Vehicles, year=2020",yes,yes,MARL
RL_evo_10,"Safe Model-Based Off-Policy Reinforcement Learning for Eco-Driving in Connected and Automated Hybrid Electric Vehicles, year=2022",yes,yes,MFRL
RL_evo_11,"Deep Reinforcement Learning Based Integrated Eco-Driving Strategy for Connected and Automated Electric Vehicles in Complex Urban Scenarios, year=2024",no,yes,NAN
RL_evo_12,"Driver Assistance Eco-driving and Transmission Control with Deep Reinforcement Learning, year=2022",yes,yes,MBRL
RL_evo_13,"connectionist reinforcement learning"", author   = ""Williams, Ronald J"", journal  = ""Machine Learning"", volume   =  8, number   =  3, pages    = ""229--256"", month    =  may, year     =  1992",yes,yes,MARL
V2X_evo_1,"Hybrid Reinforcement Learning-Based Eco-Driving Strategy for Connected and Automated Vehicles at Signalized Intersections, year=2022",no,no,NAN
Eco_1,"Deep Reinforcement Learning-Based Speed Predictor for Distributionally Robust Eco-Driving, year=2025",yes,yes,HRL
Eco_2,"Comparative Analysis of a Low-voltage CHB Inverter without PWM and Two-Level IGBT/SiC Inverters for Electric Vehicles on Driving Cycles, year=2025",yes,no,MFRL
Eco_3,"Improved Deep Reinforcement Learning for Efficient Motion Control of Autonomous Vehicle with Domain-Centralized Electronic and Electrical Architecture, year=2025",yes,yes,MBRL
Eco_4,"Supervisory controller for minimizing fuel consumption and NOx emissions of plug-in hybrid electric vehicles operating in zero-emission zones, journal = International Journal of Engine Research",yes,yes,HRL
Eco_5,"Practical Implementation and Experimental Validation of an Optimal Control based Eco-Driving System, author=Vinith Kumar Lakshmanan and Olivier Lemaire and Antonio Sciarretta",no,yes,NAN
Eco_6,"An optimization scheduling strategy for hydrogen-based integrated energy systems using multi-agent deep reinforcement learning, journal = Energy Conversion and Management",yes,yes,MARL
Eco_7,"The International Conference Optoelectronic Information and Optical Engineering (OIOE2024), editor = Yang Yue and Lu Leng",yes,yes,MFRL
Eco_8,"Hydrogen Energy Storage System Participated Decentralized Voltage Control With Multi-Agent Deep Reinforcement Learning Method, year=2025",yes,yes,MFRL
Eco_9,"Adaptive real-time control strategy for extended-range electric vehicles considering battery temperature maintenance and cabin thermal comfort in low-temperature environments, journal = International Journal of Heat and Mass Transfer",yes,yes,HRL
Eco_10,"infrastructure networks restoration with multiple crews"", author   = ""Feng, Qiang and Wu, Qilong and Hai, Xingshuo and Ren, Yi and Wen, Changyun and Wang, Zili"", journal  = ""Frontiers of Engineering Management"", month    =  jan, year     =  2025",yes,yes,MARL
Eco_11,"storage systems with compressed air and solid oxide fuel cells"", author    = ""Guan, Yundie and Zhang, Xiangyu and Liang, Zheming and Chen, Tao"", journal   = ""IET Renew. Power Gener."", publisher = ""Institution of Engineering and Technology (IET)"", volume    =  19, number    =  1, month     =  jan, year      =  2025, language  = ""en""",yes,yes,MFRL
Eco_12,"Secure State Estimation for Multi-Sensor Cyber-Physical Systems Using Virtual Sensor and Deep Reinforcement Learning Under Multiple Attacks on Major Sensor, year=2025",yes,yes,MARL
V2X,"C-V2X - A Communication Technology for Cooperative, Connected and Automated Mobility, year=2019",no,yes,NAN
V2X_2,"Enhancing Vehicular Networks With Hierarchical O-RAN Slicing and Federated DRL, year=2024",yes,no,MBRL
V2X_3,"Latency Analysis for Real-Time Sensor Sharing Using 4G/5G C-V2X Uu Interfaces, year=2023",no,yes,NAN
A3C_VMnih_2016,"Asynchronous Methods for Deep Reinforcement Learning, journal = Proceedings of the 33rd International Conference on Machine Learning",yes,yes,MARL
ACER_VMnih_sample,"Sample Efficient Actor-Critic with Experience Replay, author=Ziyu Wang and Victor Bapst and Nicolas Heess and Volodymyr Mnih and Remi Munos and Koray Kavukcuoglu and Nando de Freitas",yes,yes,MFRL
Sutton_RL,"Reinforcement Learning: An Introduction, author       = Sutton, Richard S. and Barto, Andrew G.",yes,no,MFRL
DDPG_lillicrap2016,"Proceedings of the International Conference on Learning Representations (ICLR), year         = 2016",no,no,NAN
DoubleDQN_van2016,"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, volume       = 30",yes,yes,HRL
DQN_mnih2015human,"Human-level control through deep reinforcement learning, author       = Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis",yes,yes,MARL
DuelingDQN_2016,"Proceedings of The 33rd International Conference on Machine Learning, pages = 	 1995--2003",no,yes,NAN
DYNA_Sutton1990_ADP,"Proceedings of the Seventh International Conference on Machine Learning, editor    = Bruce W. Porter and Raymond J. Mooney",yes,yes,MBRL
HER_2017,"Hindsight Experience Replay, url = https://proceedings.neurips.cc/paper_files/paper/2017/file/453fadbd8a1a3af50a9df4df899537b5-Paper.pdf",yes,yes,HRL
MADDPG,"Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments, url = https://proceedings.neurips.cc/paper_files/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf",yes,yes,MARL
MBRL2013,"A Survey on Policy Search for Robotics, author = Deisenroth, M. P. and Neumann, G. and Peters, J.",yes,yes,MFRL
PPO_2017,"Proximal Policy Optimization Algorithms, author=John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov",yes,yes,HRL
Q-Learning_Watkins,"Learning from Delayed Rewards, school       = University of Cambridge",no,yes,NAN
R2D2_2019,"Proceedings of the International Conference on Learning Representations (ICLR), year         = 2019",yes,no,MARL
SAC_2018,"Proceedings of the 35th International Conference on Machine Learning, pages        = 1861--1870",yes,yes,MBRL
SARSA_1994,"On-Line Q-Learning Using Connectionist Systems, institution = University of Cambridge",no,no,NAN
SMORL,"Safe Model-Based Off-Policy Reinforcement Learning for Eco-Driving in Connected and Automated Hybrid Electric Vehicles, year=2022",yes,yes,MFRL
TD3_TATD3_2018,"Proceedings of the 35th International Conference on Machine Learning, pages        = 1587--1596",yes,yes,MARL
TRPO_2015,"Proceedings of the 32nd International Conference on Machine Learning, pages = 	 1889--1897",no,yes,NAN
Beusen_2009,"journal=""Transportation research part D: transport and environment"", year=""2009"", author=""Beusen, Bart and Broekx, Steven and Denys, Tobias and Beckx, Carolien and Degraeuwe, Bart and Gijsbers, Maarten and Scheepers, Kristof and Govaerts, Leen and Torfs, Rudi and Panis, Luc Int"", volume=""14"", number=""7"", pages=""514-520"", issn=""1361-9209"", doi=""10.1016/j.trd.2009.05.009""",yes,yes,HRL
bogner_2021,"Eco-driving initiatives â€“ the key for sustainable and energy-efficient use of motorized vehicles, author = Thomas Bogner and Reinhard Jellinek",yes,yes,MARL
Wu,"Hybrid System Stability Analysis of Multilane Mixed-Autonomy Traffic, year=2024",yes,no,MFRL
DQN_2,"A Deep Reinforcement Learning Framework for Eco-Driving in Connected and Automated Hybrid Electric Vehicles, author=Li, Yang and Ding, Zhengtao and Shen, Yan and Zhang, Yanfeng",yes,yes,MBRL
DQN_3,"Driving Profile Optimization Using a Deep Q-Network to Enhance Electric Vehicle Battery Life, author=Kwon, J. and Kim, M. and Kim, H. and Lee, M. and Lee, S.",no,yes,NAN
DQN_4,"Hybrid Electric Vehicle Energy Management with Computer Vision and Deep Reinforcement Learning, author=Huang, Y. and Wang, Y. and Liu, X.",yes,yes,HRL
DQN_5,"Energy-Optimized Adaptive Cruise Control Strategy Design at Intersection for Electric Vehicles Based on Speed Planning, author=Li, J. and Shen, Y. and Zhang, Y.",yes,yes,MARL
DDPG_2,"Addressing Function Approximation Error in Actor-Critic Methods, author=Scott Fujimoto and Herke van Hoof and David Meger",yes,yes,MFRL
DDPG_3,"Deep Deterministic Policy Gradient Based Energy Management Strategy for Hybrid Electric Tracked Vehicle With Online Updating Mechanism, year=2021",no,no,NAN
DDPG_4,"Continuous Reinforcement Learning-Based Energy Management Strategy for Hybrid Electric-Tracked Vehicles, year=2023",yes,yes,MBRL
DDPG_5,"Delayed Deep Deterministic Policy Gradient-Based Energy Management Strategy for Overall Energy Consumption Optimization of Dual Motor Electrified Powertrain, year=2023",yes,yes,HRL
DDPG_6,"Double Deep Reinforcement Learning-Based Energy Management for a Parallel Hybrid Electric Vehicle With Engine Startâ€“Stop Strategy, year=2022",yes,yes,HRL
DDPG_7,"Multi-Agent Deep Reinforcement Learning-Based Multi-Objective Cooperative Control Strategy for Hybrid Electric Vehicles, year=2024",yes,yes,MARL
DDPG_8,"Continuous Decision-Making in Lane Changing and Overtaking Maneuvers for Unmanned Vehicles: A Risk-Aware Reinforcement Learning Approach With Task Decomposition, year=2024",no,no,NAN
DDPG_9,"Longitudinal Control of Automated Vehicles: A Novel Approach by Integrating Deep Reinforcement Learning With Intelligent Driver Model, year=2024",yes,yes,MBRL
DDPG_10,"Online-Learning Adaptive Energy Management for Hybrid Electric Vehicles in Various Driving Scenarios Based on Dyna Framework, year=2024",yes,yes,HRL
DDPG_11,"Blockchain-Secured Task Offloading and Resource Allocation for Cloud-Edge-End Cooperative Networks, author=Wenhao Fan, Zhibo Hao, Bihua Tang, Fan Wu, and Yuanâ€™an Liu",yes,yes,MARL
DDPG_12,"Cooperative Task Offloading and Block Mining in Blockchain-Based Edge Computing With Multi-Agent Deep Reinforcement Learning, year=2023",no,yes,NAN
DDPG_13,"Machine-Learning-Based Optimal Cooperating Node Selection for Internet of Underwater Things, year=2024",yes,yes,MFRL
DDPG_14,"Artificial intelligence for hydrogen-enabled integrated energy systems: A systematic review, journal = International Journal of Hydrogen Energy",yes,yes,MBRL
DDPG_15,"Battery Health-Aware and Deep Reinforcement Learning-Based Energy Management for Naturalistic Data-Driven Driving Scenarios, year=2022",yes,yes,MARL
DDPG_16,"DNN Assisted Projection Based Deep Reinforcement Learning for Safe Control of Distribution Grids, year=2024",yes,no,MFRL
DDPG_17,"MADDPG-Based Joint Service Placement and Task Offloading in MEC Empowered Airâ€“Ground Integrated Networks, year=2024",yes,yes,HRL
DDPG_18,"Signal Compensation Control With DDPG-Based Tuning Strategy for Electronic Throttle System, year=2024",no,no,NAN
DDPG_19,"Speed Fluctuation Suppression Control of Super-High-Speed Electric Air Compressors Considering High-Frequency Electromagnetic Excitation, year=2024",yes,yes,MFRL
DDPG_20,"Task Offloading and Resource Allocation for Fog Computing in NG Wireless Networks: A Federated Deep Reinforcement Learning Approach, year=2024",yes,yes,HRL
DDPG_21,"Throughput Maximization for RF Powered Cognitive NOMA Networks With Backscatter Communication by Deep Reinforcement Learning, year=2024",yes,yes,MARL
DQN_6,"FECO: An Efficient Deep Reinforcement Learning-Based Fuel-Economic Traffic Signal Control Scheme, author=Zhang, X. and Wang, Y. and Liu, Y.",yes,no,MBRL
Dyna_Scenarios,"Online-Learning Adaptive Energy Management for Hybrid Electric Vehicles in Various Driving Scenarios Based on Dyna Framework, year=2024",no,yes,NAN
Dyna_Trainer,"Intelligent Trainer for Dyna-Style Model-Based Deep Reinforcement Learning, year=2021",yes,yes,HRL
Dyna_PEV,"Autonomous PEV Charging Scheduling Using Dyna-Q Reinforcement Learning, year=2020",yes,yes,MARL
Dyna_DeepDynaRL,"Deep Dyna-Reinforcement Learning Based on Random Access Control in LEO Satellite IoT Networks, year=2022",yes,yes,MFRL
Dyna_safeRL,"Safe Reinforcement Learning for Model-Reference Trajectory Tracking of Uncertain Autonomous Vehicles With Model-Based Acceleration, year=2023",no,yes,NAN
Dyna_Sutton1990,"Dyna, an integrated architecture for learning, planning, and reacting, author=Richard S. Sutton",yes,yes,HRL
Dyna_EMS,"Energy Management for a Hybrid Electric Vehicle Based on Blended Reinforcement Learning With Backward Focusing and Prioritized Sweeping, year=2021",yes,yes,MARL
PPO_1,"Power Control of 5G-Connected Vehicular Network Using PPO-Based Deep Reinforcement Learning Algorithm, year=2024",yes,no,MFRL
PPO_2,"Adaptive Traffic Light Control With Deep Reinforcement Learning: An Evaluation of Traffic Flow and Energy Consumption, year=2023",yes,yes,MBRL
PPO_3,"A Deep Reinforcement Learning Framework for Eco-Driving in Connected and Automated Hybrid Electric Vehicles, year=2024",no,yes,NAN
PPO_4,"A Proximal Policy Optimization Based Control Framework for Flexible Battery Energy Storage System, year=2024",yes,yes,HRL
PPO_5,"A Reinforcement Learning-Based Pantograph Control Strategy for Improving Current Collection Quality in High-Speed Railways, year=2024",yes,yes,MARL
PPO_6,"A Reinforcement Learning-Based Vehicle Platoon Control Strategy for Reducing Energy Consumption in Traffic Oscillations, year=2021",yes,no,MBRL
PPO_7,"Adaptive Metro Service Schedule and Train Composition With a Proximal Policy Optimization Approach Based on Deep Reinforcement Learning, year=2022",no,no,NAN
PPO_8,"Energy-Efficient Driving for Adaptive Traffic Signal Control Environment via Explainable Reinforcement Learning, JOURNAL = Applied Sciences",yes,yes,HRL
PPO_9,"An Empirical Study of DDPG and PPO-Based Reinforcement Learning Algorithms for Autonomous Driving, year=2023",yes,yes,MARL
PPO_10,"Centralized Cooperation for Connected and Automated Vehicles at Intersections by Proximal Policy Optimization, year=2020",yes,yes,MFRL
PPO_11,"Communication Scheduling by Deep Reinforcement Learning for Remote Traffic State Estimation With Bayesian Inference, year=2022",yes,yes,HRL
PPO_12,"An Energy-Efficient Driving Method for Connected and Automated Vehicles Based on Reinforcement Learning, JOURNAL = Machines",no,yes,NAN
PPO_13,"Coordination for Connected and Automated Vehicles at Non-Signalized Intersections: A Value Decomposition-Based Multiagent Deep Reinforcement Learning Approach, year=2023",yes,yes,MBRL
PPO_14,"Dyna-PPO reinforcement learning with Gaussian process for the continuous action decision-making in autonomous driving"", author   = ""Wu, Guanlin and Fang, Wenqi and Wang, Ji and Ge, Pin and Cao, Jiang and Ping, Yang and Gou, Peng"", journal  = ""Applied Intelligence"", volume   =  53, number   =  13, pages    = ""16893--16907"", month    =  jul, year     =  2023",yes,yes,HRL
PPO_15,"A distributed multi-vehicle pursuit scheme: generative multi-adversarial reinforcement learning, year = 2023",yes,yes,MARL
PPO_16,"Deep Reinforcement Learning for Multi-Objective Resource Allocation in Multi-Platoon Cooperative Vehicular Networks, year=2023",no,yes,NAN
PPO_17,"Deep Reinforcement Learning on Autonomous Driving Policy With Auxiliary Critic Network, year=2023",yes,yes,MBRL
PPO_18,"Deep Reinforcement Learning-Based Charging Price Determination Considering the Coordinated Operation of Hydrogen Fuel Cell Electric Vehicle, Power Network and Transportation Network, year=2023",yes,no,MFRL
PPO_19,"Trajectory Planning for Multiple Autonomous Vehicles at Short-Distance Tandem Signalized Intersections Based on Rule-Free Framework, year = 2024",yes,yes,HRL
PPO_20,"Learning-Based Energy Management for Hybrid Power Systems: State-of-the-Art Survey, Review, and Perspectives""",yes,yes,MARL
PPO_21,"EPtask: Deep Reinforcement Learning Based Energy-Efficient and Priority-Aware Task Scheduling for Dynamic Vehicular Edge Computing, year=2024",yes,no,MFRL
PPO_22,"Event-Triggered Model Predictive Control With Deep Reinforcement Learning for Autonomous Driving, year=2024",yes,yes,MBRL
PPO_23,"Graph Attention Networkâ€“Based Deep Reinforcement Learning Scheduling Framework for in-Vehicle Time-Sensitive Networking, year=2024",yes,yes,MARL
PPO_24,"Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?, author=Zemian Ke and Qiling Zou and Jiachao Liu and Sean Qian",no,yes,NAN
PPO_25,"Reasoning Graph: A Situation-aware framework for cooperating unprotected turns under mixed connected and autonomous traffic environments, journal = Transportation Research Part C: Emerging Technologies",yes,yes,MFRL
PPO_26,"Deep Reinforcement Learning"", author    = ""Xu Ming and Zuo Dongyu and Li Jinye""",no,yes,NAN
PPO_27,"Reinforcement Learning-Based Intelligent Traffic Signal Control Considering Sensing Information of Railway, year=2023",yes,yes,HRL
SAC_Base,"Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor, author=Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine",yes,yes,MBRL
SAC_2,"An improved soft actor-critic based energy management strategy of fuel cell hybrid electric vehicle, journal = Journal of Energy Storage",yes,yes,MARL
SAC_3,"Data-driven energy management system for flexible operation of hydrogen/ammonia-based energy hub: A deep reinforcement learning approach, journal = Energy Conversion and Management",yes,yes,MFRL
SAC_4,"Eco-driving strategy for fuel cell vehicles in car-following scenarios considering stack heat and durability based on SAC, journal = Energy Conversion and Management",yes,yes,HRL
SAC_5,"Energy management strategy with mutation protection for fuel cell electric vehicles"", journal = International Journal of Hydrogen Energy",no,yes,NAN
SAC_6,"Cooperative energy management and eco-driving of plug-in hybrid electric vehicle via multi-agent reinforcement learning, journal = Applied Energy",yes,yes,MBRL
SAC_7,"A Discrete Soft Actor-Critic Decision-Making Strategy With Sample Filter for Freeway Autonomous Driving, year=2023",yes,no,MFRL
SAC_8,"Autonomous Vehicle Cut-In Algorithm for Lane-Merging Scenarios via Policy-Based Reinforcement Learning Nested Within Finite-State Machine, year=2022",no,yes,NAN
SAC_9,"Augmenting Reinforcement Learning with Transformer-based Scene Representation Learning for Decision-making of Autonomous Driving, author=Haochen Liu and Zhiyu Huang and Xiaoyu Mo and Chen Lv",yes,yes,MARL
SAC_10,"A survey on urban traffic control under mixed traffic environment with connected automated vehicles, journal = Transportation Research Part C: Emerging Technologies",yes,yes,HRL
SAC_11,"Distributional Soft Actor-Critic-Based Multi-AUV Cooperative Pursuit for Maritime Security Protection, volume = PP",no,yes,NAN
SAC_12,"Centroid-Guided Target-Driven Topology Control Method for UAV Ad-Hoc Networks Based on Tiny Deep Reinforcement Learning Algorithm, year=2024",yes,yes,MARL
SAC_14,"A soft actor-critic deep reinforcement learning method for multi-timescale coordinated operation of microgrids, year=2022",yes,yes,MFRL
SAC_13,"Adaptive Drift Control of Autonomous Electric Vehicles After Brake System Failures, year=2024",yes,no,MBRL
A3C_2,"A Dynamic Deep Reinforcement Learning-Bayesian Framework for Anomaly Detection, year=2022",yes,yes,HRL
A3C_3,"Power Control Based on Deep Reinforcement Learning for Spectrum Sharing, year=2020",yes,yes,MARL
A3C_4,"Increasing GPS Localization Accuracy With Reinforcement Learning, year=2021",no,yes,NAN
A3C_5,"Learning-Based Energy Management for Hybrid Power Systems: State-of-the-Art Survey, Review, and Perspectives""",yes,yes,MFRL
A3C_6,"Dynamic Scheduling for Stochastic Edge-Cloud Computing Environments Using A3C Learning and Residual Recurrent Neural Networks, year=2022",yes,no,HRL
A3C_7,"Cooperative Computation Offloading and Resource Management for Vehicle Platoon: A Deep Reinforcement Learning Approach, year=2022",yes,yes,MBRL
A3C_8,"Intelligent Resource Allocation for Video Analytics in Blockchain-Enabled Internet of Autonomous Vehicles With Edge Computing, year=2022",yes,yes,MARL
A3C_9,"Effect of immediate reward function on the performance of reinforcement learning-based energy management system, year=2022",no,yes,NAN
A3C_10,"Digital Twin-Enabled Efficient Federated Learning for Collision Warning in Intelligent Driving, year=2024",yes,yes,HRL
A3C_11,"Real-Time Optimal Energy Management of Multimode Hybrid Electric Powertrain With Online Trainable Asynchronous Advantage Actorâ€“Critic Algorithm, journal   = IEEE Transactions on Vehicular Technology",yes,yes,MARL
A3C_12,"An Efficient Reconfigurable Battery Network based on the Asynchronous Advantage Actor-Critic Paradigm, year=2024",yes,yes,MFRL
A3C_13,"Distributed Deep Reinforcement Learning-Based Energy and Emission Management Strategy for Hybrid Electric Vehicles, year=2021",no,yes,NAN
A3C_14,"Learn to Schedule: Data Freshness-Oriented Intelligent Scheduling in Industrial IoT, year=2024",yes,no,HRL
A3C_15,"Asynchronous Federated Learning for Resource Allocation in Software-Defined Internet of UAVs, year=2024",yes,yes,MBRL
A3C_16,"Asynchronous deep reinforcement learning with gradient sharing for State of Charge balancing of multiple batteries in cyberâ€“physical electric vehicles, journal = Journal of the Franklin Institute",yes,yes,HRL
A3C_17,"Towards optimal positioning and energy-efficient UAV path scheduling in IoT applications, journal = Computer Communications",yes,yes,MARL
A3C_18,"UAV-assisted vehicle edge computing networks through a digital twin-driven task offloading framework"", author   = ""Zhang, Zhiyang and Zhang, Fengli and Cao, Minsheng and Feng, Chaosheng and Chen, Dajiang"", journal  = ""Wireless Networks"", month    =  jul, year     =  2024",yes,yes,MFRL
A3C_19,"AI-big data analytics for building automation and management systems: a survey, actual challenges and future perspectives"", author   = ""Himeur, Yassine and Elnour, Mariam and Fadli, Fodil and Meskin, Nader and Petri, Ioan and Rezgui, Yacine and Bensaali, Faycal and Amira, Abbes"", journal  = ""Artificial Intelligence Review"", volume   =  56, number   =  6, pages    = ""4929--5021"", month    =  jun, year     =  2023",yes,no,MBRL
A3C_20,"author   = ""Zhang, Liang and Chen, Zhelun and Zhang, Xiangyu and Pertzborn, Amanda and Jin, Xin"", journal  = ""Building Simulation"", volume   =  16, number   =  6, pages    = ""831--852"", month    =  jun, year     =  2023",yes,yes,HRL
A3C_21,"author   = ""Benchikh, Lina and Louail, Lemia and Mechta, Djamila"", journal  = ""Energy Systems"", month    =  apr, year     =  2024",no,yes,NAN
A3C_22,"Asynchronous deep reinforcement learning with gradient sharing for State of Charge balancing of multiple batteries in cyberâ€“physical electric vehicles, journal = Journal of the Franklin Institute",yes,yes,MFRL
A3C_23,"Towards optimal positioning and energy-efficient UAV path scheduling in IoT applications, journal = Computer Communications",yes,yes,MARL
A3C_24,"Reinforcement learning in deregulated energy market: A comprehensive review, journal = Applied Energy",yes,yes,MBRL
A3C_25,"UAV-assisted vehicle edge computing networks through a digital twin-driven task offloading framework"", author   = ""Zhang, Zhiyang and Zhang, Fengli and Cao, Minsheng and Feng, Chaosheng and Chen, Dajiang"", journal  = ""Wireless Networks"", month    =  jul, year     =  2024",yes,yes,HRL
A3C_26,"Energy-Efficient Data Offloading Strategy for 5G-Enabled Vehicular Edge Computing Networks Using Double Deep Q-Network"", author   = ""Moghaddasi, Komeil and Rajabi, Shakiba and Soleimanian Gharehchopogh, Farhad and Hosseinzadeh, Mehdi"", journal  = ""Wireless Personal Communications"", volume   =  133, number   =  3, pages    = ""2019--2064"", month    =  dec, year     =  2023",yes,yes,MARL
A3C_27,"Adaptive Video Streaming With Edge Caching and Video Transcoding Over Software-Defined Mobile Networks: A Deep Reinforcement Learning Approach, year=2020",no,yes,NAN
TD3_2,"Deep Reinforcement Learning based Energy Management for Heavy Duty HEV considering Discrete-Continuous Hybrid Action Space, year=2024",yes,yes,MFRL
TD3_3,"An improved energy management strategy for hybrid electric powered aircraft based on deep reinforcement learning, journal = Aerospace Science and Technology",yes,yes,HRL
TD3_4,"Deep reinforcement learning for autonomous driving in uncontrolled intersections of Indian roads, journal = Multimedia Tools and Applications",yes,no,MBRL
TD3_5,"Deep Reinforcement Learning With Multiple Unrelated Rewards for AGV Mapless Navigation, volume = PP",yes,yes,MARL
TD3_6,"DNN Assisted Projection Based Deep Reinforcement Learning for Safe Control of Distribution Grids, year=2024",yes,yes,MFRL
TRPO_2,"Constrained Policy Optimization Algorithm for Autonomous Driving via Reinforcement Learning, year=2021",yes,no,HRL
TRPO_3,"Deep Reinforcement Learning-based Continuous Control for Multicopter Systems, year=2019",no,yes,NAN
TRPO_4,"Consumer-Centric Home Energy Management System Using Trust Region Policy Optimization- Based Multi-Agent Deep Reinforcement Learning, year=2023",yes,yes,MBRL
TRPO_5,Decision Making for Autonomous Driving Stack: Shortening the Gap from Simulation to Real-World Implementations,yes,yes,HRL
TRPO_6,"Improving Safety in Deep Reinforcement Learning using Unsupervised Action Planning, year=2022",yes,yes,MFRL
TRPO_7,"Autonomous Intersection Management with Heterogeneous Vehicles: A Multi-Agent Reinforcement Learning Approach, year=2024",no,yes,NAN
ACER_2,"Learning to Delay in Ride-Sourcing Systems: A Multi-Agent Deep Reinforcement Learning Framework, year=2022",yes,yes,HRL
ACER_3,"On-Policy vs. Off-Policy Deep Reinforcement Learning for Resource Allocation in Open Radio Access Network, year=2022",yes,yes,MARL
ACER_4,"ACERAC: Efficient Reinforcement Learning in Fine Time Discretization, year=2024",yes,yes,MBRL
Dueling_DQN_2,"The USV Path Planning of Dueling DQN Algorithm Based on Tree Sampling Mechanism, year=2022",yes,no,MFRL
Dueling_DQN_3,"Task Offloading via Prioritized Experience-based Double Dueling DQN in Edge-assisted IIoT, year=2024",yes,yes,HRL
Dueling_DQN_4,"Unmanned Aerial Vehicle Autonomous Visual Landing through Visual Attention-Based Deep Reinforcement Learning, year=2023",no,yes,NAN
Dueling_DQN_5,"V-D D3QN: the Variant of Double Deep Q-Learning Network with Dueling Architecture, year=2018",yes,yes,MFRL
DoubleDQN_2,"Deep reinforcement learning for autonomous vehicles: lane keep and overtaking scenarios with collision avoidance, author=Ashwin, S. H. and Raj, Rashmi N.",yes,yes,HRL
DoubleDQN_3,"Vehicular communication using federated learning empowered chimp optimization (FLECO) algorithm, author=Gupta, R. and Alam, T.",yes,yes,MARL
DoubleDQN_4,"Real-Time Battery Thermal Management for Electric Vehicles Based on Deep Reinforcement Learning, author=Huang, G. and Zhao, P. and Zhang, G.",yes,no,MBRL
DoubleDQN_5,"An Enhanced Dueling Double Deep Q-Network With Convolutional Block Attention Module for Traffic Signal Optimization in Deep Reinforcement Learning, author=Peng Wang and Wenlong Ni",no,yes,NAN
DoubleDQN_6,"Dynamic joint optimization of power generation and voyage scheduling in ship power systems based on deep reinforcement learning, author=Shang, C. and Fu, L. and Bao, X. and Xiao, H. and Xu, X. and Hu, Q.",yes,yes,MFRL
DoubleDQN_7,"Enhanced Traffic Signal Optimization Using Dueling Double Deep Q Networks, author=Lee, D. and Wang, X.",yes,yes,HRL
DoubleDQN_8,"Energy-Saving Design of Underground Metro Vertical Alignment With Deep Reinforcement Learning, author=Xu, Shuangting and Gao, Tianci and Yang, Dongying",yes,yes,MARL
DoubleDQN_9,"Challenges in scaling reinforcement learning for ITS, author=Zhang, Y. and Wang, L.",no,yes,NAN
MADDPG2,"Multi-Agent Deep Reinforcement Learning-Based Multi-Objective Cooperative Control Strategy for Hybrid Electric Vehicles, year=2024",yes,yes,MBRL
MADDPG3,"Ecological Driving Framework of Hybrid Electric Vehicle Based on Heterogeneous Multi-Agent Deep Reinforcement Learning, year=2024",yes,yes,HRL
MADDPG4,"Cooperative energy management and eco-driving of plug-in hybrid electric vehicle via multi-agent reinforcement learning, journal = Applied Energy",yes,yes,MARL
MADDPG5,"Lane-Changing Tracking Control of Automated Vehicle Platoon Based on MA-DDPG and Adaptive MPC, year=2024",no,yes,NAN
MADDPG6,"Digital-Twin-Based Deep Reinforcement Learning Approach for Adaptive Traffic Signal Control, year=2024",yes,yes,HRL
MADDPG7,"Data-Efficient MADDPG Based on Self-Attention for IoT Energy Management Systems, year=2023",yes,yes,MARL
MADDPG8,"Multi-Agent Graph Reinforcement Learning Method for Electric Vehicle on-Route Charging Guidance in Coupled Transportation Electrification, year=2024",yes,no,MBRL
MADDPG9,"Multiagent Deep Deterministic Policy Gradient-Based Computation Offloading and Resource Allocation for ISAC-Aided 6G V2X Networks, year=2024",no,yes,NAN
MADDPG10,"Optimization of Peer-to-Peer Energy Trading With a Model-Based Deep Reinforcement Learning in a Non-Sharing Information Scenario, year=2024",yes,yes,MFRL
MADDPG11,"Privacy Preserving Demand Side Management Method via Multi-Agent Reinforcement Learning, year=2023",yes,yes,HRL
MADDPG12,"Multi-Agent Learning-Based Optimal Task Offloading and UAV Trajectory Planning for AGIN-Power IoT, year=2023",yes,yes,MARL
MADDPG13,"Cooperative Task Offloading and Block Mining in Blockchain-Based Edge Computing With Multi-Agent Deep Reinforcement Learning, year=2023",no,yes,NAN
MADDPG14,"An Attention Mechanism and Adaptive Accuracy Triple-Dependent MADDPG Formation Control Method for Hybrid UAVs, year=2024",yes,yes,MBRL
MADDPG15,"Multi-UAV Collaborative Edge Computing Algorithm for Joint Task Offloading and Channel Resource Allocation, year=2024",yes,no,MFRL
MADDPG16,"Bandwidth Allocation and Trajectory Control in UAV-Assisted IoV Edge Computing Using Multiagent Reinforcement Learning, year=2023",yes,yes,HRL
MADDPG17,"Revenue and Energy Efficiency-Driven Delay-Constrained Computing Task Offloading and Resource Allocation in a Vehicular Edge Computing Network: A Deep Reinforcement Learning Approach, year=2022",yes,yes,MARL
MADDPG18,"Multi-Agent Reinforcement Learning for Slicing Resource Allocation in Vehicular Networks, year=2024",yes,yes,MFRL
MADDPG19,"AoI-Aware Resource Allocation for Platoon-Based C-V2X Networks via Multi-Agent Multi-Task Reinforcement Learning, year=2023",no,yes,NAN
MADDPG20,"Two-Hop Packet Scheduling, Resource Allocation, and UAV Trajectory Design for Internet of Remote Things in Airâ€“Ground Integrated Network, year=2024",yes,yes,HRL
MADDPG21," Collaborative Overtaking Strategy for Enhancing Overall Effectiveness of Mixed Connected and Connectionless Vehicles , year=2024",yes,yes,MARL
MADDPG22,"MARRGM: Learning Framework for Multi-Agent Reinforcement Learning via Reinforcement Recommendation and Group Modification, year=2024",yes,no,MBRL
MADDPG23,"Distributed Routing Optimization Algorithm for FANET Based on Multiagent Reinforcement Learning, year=2024",yes,yes,MFRL
MADDPG24,"Multi-Agent DRL-Controlled Connected and Automated Vehicles in Mixed Traffic With Time Delays, volume = PP",no,yes,NAN
MADDPG25,"Matching Combined Heterogeneous Multi-Agent Reinforcement Learning for Resource Allocation in NOMA-V2X Networks, year=2024",yes,yes,HRL
HER_2,"Battery-Aware Cooperative Merging Strategy of Connected Electric Vehicles Based on Reinforcement Learning With Hindsight Experience Replay, year=2022",yes,yes,MARL
HER_3,"Energy Harvesting UAV-RIS-Assisted Maritime Communications Based on Deep Reinforcement Learning Against Jamming, year=2024",yes,no,MFRL
HER_4,"Guided deep reinforcement learning framework using automated curriculum scheme for accurate motion planning, journal = Engineering Applications of Artificial Intelligence",yes,yes,MBRL
HER_5,"Emergency Fire Escape Path Planning Model Based on Improved DDPG Algorithm, author=Feng, Zengxi and others",no,yes,NAN
HER_6,"Cognitive Intelligence in Industrial Robots and Manufacturing, author=Mukherjee, Avishek and others",yes,yes,HRL
R2D2_2,"A Time-Adaptive Method to Transient Stability Assessment Based on Reinforcement Learning, doi = 10.1109/PowerCon58120.2023.10331116",yes,yes,MARL
R2D2_3,"Modern Value Based Reinforcement Learning: A Chronological Review, year=2022",yes,no,MBRL
TATD3_2,"Safe Reinforcement Learning for Energy Management of Electrified Vehicle With Novel Physics-Informed Exploration Strategy, year=2024",yes,yes,MFRL
TATD3_3,"A practically implementable reinforcement learning control approach by leveraging offset-free model predictive control, journal = Computers & Chemical Engineering",no,yes,NAN
TATD3_4,"A-TD3: An Adaptive Asynchronous Twin Delayed Deep Deterministic for Continuous Action Spaces, year=2022",yes,yes,HRL
TATD3_5,"Twin actor twin delayed deep deterministic policy gradient (TATD3) learning for batch process control, journal = Computers & Chemical Engineering",yes,yes,MARL
SMORL_2,"Large Language Model-Powered Digital Traffic Engineers: The Framework and Case Studies, year=2024",yes,no,MFRL
SMORL_3,"Safe Reinforcement Learning in Autonomous Driving With Epistemic Uncertainty Estimation, year=2024",no,yes,NAN
SMORL_4,"Deep Reinforcement Learning for Intelligent Energy Management Systems of Hybrid-Electric Powertrains: Recent Advances, Open Issues, and Prospects, year=2024",yes,yes,MBRL
SMORL_5,"Progression Cognition Reinforcement Learning With Prioritized Experience for Multi-Vehicle Pursuit, year=2024",yes,yes,HRL
SMORL_6,"A Bi-Level Network-Wide Cooperative Driving Approach Including Deep Reinforcement Learning-Based Routing, year=2024",yes,yes,MARL
SMORL_7,"Guided Eco-Driving of Fuel Cell Hybrid Electric Vehicles via Model Predictive Control, year=2023",yes,no,MBRL
SMORL_8,"Deep Reinforcement Learning-Based Energy-Efficient Decision-Making for Autonomous Electric Vehicle in Dynamic Traffic Environments, year=2024",yes,yes,MFRL
SMORL_9,"NMPC-Based Integrated Thermal Management of Battery and Cabin for Electric Vehicles in Cold Weather Conditions, year=2023",no,yes,NAN
SMORL_10,"BlindSpotEliminator: Collaborative Point Cloud Perception in Cellular-V2X Networks, year=2023",yes,yes,HRL
SMORL_11,"Energy efficient speed planning of electric vehicles for car-following scenario using model-based reinforcement learning, journal = Applied Energy",yes,yes,MARL
SMORL_12,"Energy-efficient powertrain control of an automated and connected power-split HEV in an urban environment, journal = IFAC-PapersOnLine",yes,no,MBRL
AC_2,"Cooperative Computation Offloading and Resource Management for Vehicle Platoon: A Deep Reinforcement Learning Approach, year=2022",no,yes,NAN
AC_3,"Deep Reinforcement Learning Based Integrated Eco-Driving Strategy for Connected and Automated Electric Vehicles in Complex Urban Scenarios, year=2024",yes,yes,MFRL
AC_4,"Economic Adaptive Cruise Control for Electric Vehicles Based on ADHDP in a Car-Following Scenario, year=2021",yes,yes,HRL
AC_5,"DRL-KeyAgree: An Intelligent Combinatorial Deep Reinforcement Learning-Based Vehicular Platooning Secret Key Generation, year=2024",yes,yes,MARL
AC_6,"Reward Shaping-Based Actorâ€“Critic Deep Reinforcement Learning for Residential Energy Management, year=2023",yes,no,MFRL
AC_7,"Attention-Based Distributional Reinforcement Learning for Safe and Efficient Autonomous Driving, year=2024",no,yes,NAN
AC_8,"Power Control of 5G-Connected Vehicular Network Using PPO-Based Deep Reinforcement Learning Algorithm, year=2024",yes,yes,MBRL
AC_9,"Single-Loop Deep Actor-Critic for Constrained Reinforcement Learning With Provable Convergence, year=2024",yes,no,HRL
AC_10,"5G NR Codes and Modulation Deep-RL Optimization for uRLLC in Vehicular OCC, year=2024",yes,yes,MARL
AC_11,"DT-LNS: Digital-Twin-Based Low-Risk Network Slicing Using Safe Reinforcement Learning, year=2024",yes,yes,MFRL
AC_12,"CM3-VSL: Cooperative Multi-goal Multi-stage Multi-agent VSL Traffic Control"", author   = ""Rhanizar, Asmae and El Akkaoui, Zineb"", journal  = ""International Journal of Intelligent Transportation Systems Research"", volume   =  22, number   =  3, pages    = ""720--734"", month    =  dec, year     =  2024",no,yes,NAN
AC_13,"double-DQN approaches for intelligent task offloading"", author   = ""Ullah, Ihsan and Han, Youn-Hee"", journal  = ""The Journal of Supercomputing"", volume   =  81, number   =  1, pages    = ""76"", month    =  oct, year     =  2024",yes,yes,HRL
AC_14,"CM3-VSL: Cooperative Multi-goal Multi-stage Multi-agent VSL Traffic Control"", author   = ""Rhanizar, Asmae and El Akkaoui, Zineb"", journal  = ""International Journal of Intelligent Transportation Systems Research"", volume   =  22, number   =  3, pages    = ""720--734"", month    =  dec, year     =  2024",yes,yes,MARL
AC_15,"Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages = 3162â€“3172",yes,no,MFRL
AC_16,"Smart EV Charging With Context-Awareness: Enhancing Resource Utilization via Deep Reinforcement Learning, year=2024",yes,yes,HRL
QL_3,"Rate GQN: A Deviations-Reduced Decision-Making Strategy for Connected and Automated Vehicles in Mixed Autonomy, year=2024",yes,yes,MARL
QL_4,"Optimal Energy Management of Plug-in Hybrid Electric Vehicles Through Ensemble Reinforcement Learning With Exploration-to-Exploitation Ratio Control, year=2024",no,yes,NAN
QL_5,"Enhancing the Fuel-Economy of V2I-Assisted Autonomous Driving: A Reinforcement Learning Approach, year=2020",yes,yes,MFRL
QL_6,"Meta-Deep Q-Learning for Eco-Routing, year=2019",yes,yes,MFRL
QL_7,"Traffic-Aware Adaptive Routing for Minimizing Fuel Consumption, year=2019",yes,yes,MFRL
QL_8,"Multi-timescale Reward-based DRL Energy Management for Regenerative Braking Energy Storage System, year=2025",yes,yes,MFRL
QL_9,"Towards Secure and Efficient Data Scheduling for Vehicular Social Networks, year=2025",yes,yes,MFRL
